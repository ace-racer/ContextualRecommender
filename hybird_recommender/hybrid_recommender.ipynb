{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StreamID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507</td>\n",
       "      <td>wBYKUgUyGWc\\r\\nA team of world-class drivers, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>Castrol EDGE  is Castrol?s flagship power bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>Charles ?Cheers? Wakefield, Castrol?s founder,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StreamID                                            Content\n",
       "0       163  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...\n",
       "1       419  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...\n",
       "2       507  wBYKUgUyGWc\\r\\nA team of world-class drivers, ...\n",
       "3       199  Castrol EDGE  is Castrol?s flagship power bran...\n",
       "4       201  Charles ?Cheers? Wakefield, Castrol?s founder,..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_content_df = pd.read_csv(\"data/stream_content.csv\", header=0, encoding=\"ISO-8859-1\")\n",
    "stream_content_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the content to remove stop words, punctutations and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StreamID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...</td>\n",
       "      <td>[txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...</td>\n",
       "      <td>[txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507</td>\n",
       "      <td>wBYKUgUyGWc\\r\\nA team of world-class drivers, ...</td>\n",
       "      <td>[wbykuguygwc, team, world-class, driver, power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>Castrol EDGE  is Castrol?s flagship power bran...</td>\n",
       "      <td>[castrol, edge, castrol, flagship, power, bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>Charles ?Cheers? Wakefield, Castrol?s founder,...</td>\n",
       "      <td>[charles, cheer, wakefield, castrol, founder, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StreamID                                            Content  \\\n",
       "0       163  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...   \n",
       "1       419  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...   \n",
       "2       507  wBYKUgUyGWc\\r\\nA team of world-class drivers, ...   \n",
       "3       199  Castrol EDGE  is Castrol?s flagship power bran...   \n",
       "4       201  Charles ?Cheers? Wakefield, Castrol?s founder,...   \n",
       "\n",
       "                                   Content_processed  \n",
       "0  [txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...  \n",
       "1  [txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...  \n",
       "2  [wbykuguygwc, team, world-class, driver, power...  \n",
       "3  [castrol, edge, castrol, flagship, power, bran...  \n",
       "4  [charles, cheer, wakefield, castrol, founder, ...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(tokens):\n",
    "    \n",
    "    # TODO: remove random sequences that contain with more than one caps and small or combination of letters and numbers\n",
    "    \n",
    "    tokens_nop = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens_nop = [t.lower() for t in tokens_nop]\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    stop = stopwords.words('english')\n",
    "    tokens_nostop = [t for t in tokens_nop if t not in stop]\n",
    "    tokens_lem = [wnl.lemmatize(t) for t in tokens_nostop]\n",
    "    tokens_clean = [t for t in tokens_lem if len(t) >= 3] \n",
    "    return tokens_clean\n",
    "\n",
    "stream_content_df['Content_processed'] = stream_content_df['Content'].map(word_tokenize)\n",
    "stream_content_df['Content_processed'] = stream_content_df.Content_processed.apply(preprocess)\n",
    "stream_content_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the TFIDF vectors for the streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StreamID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...</td>\n",
       "      <td>txmak2kzay4 nmeujebo1ac eeutxfhp3go castrol la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...</td>\n",
       "      <td>txmak2kzay4 nmeujebo1ac eeutxfhp3go castrol la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507</td>\n",
       "      <td>wBYKUgUyGWc\\r\\nA team of world-class drivers, ...</td>\n",
       "      <td>wbykuguygwc team world-class driver powered ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>Castrol EDGE  is Castrol?s flagship power bran...</td>\n",
       "      <td>castrol edge castrol flagship power brand pcos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>Charles ?Cheers? Wakefield, Castrol?s founder,...</td>\n",
       "      <td>charles cheer wakefield castrol founder entrep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StreamID                                            Content  \\\n",
       "0       163  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...   \n",
       "1       419  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...   \n",
       "2       507  wBYKUgUyGWc\\r\\nA team of world-class drivers, ...   \n",
       "3       199  Castrol EDGE  is Castrol?s flagship power bran...   \n",
       "4       201  Charles ?Cheers? Wakefield, Castrol?s founder,...   \n",
       "\n",
       "                                   Content_processed  \n",
       "0  txmak2kzay4 nmeujebo1ac eeutxfhp3go castrol la...  \n",
       "1  txmak2kzay4 nmeujebo1ac eeutxfhp3go castrol la...  \n",
       "2  wbykuguygwc team world-class driver powered ca...  \n",
       "3  castrol edge castrol flagship power brand pcos...  \n",
       "4  charles cheer wakefield castrol founder entrep...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_content_df['Content_processed'] = stream_content_df['Content_processed'].apply(lambda x: \" \".join(x))\n",
    "stream_content_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<97x928 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6122 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_streams_cleaned_text = stream_content_df['Content_processed']\n",
    "all_streams_tfidf_vectorizer = TfidfVectorizer(min_df = 2)\n",
    "all_streams_tfidf = all_streams_tfidf_vectorizer.fit_transform(all_streams_cleaned_text)\n",
    "all_streams_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_values = {all_streams_tfidf_vectorizer.vocabulary_[token]: token for token in all_streams_tfidf_vectorizer.vocabulary_}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(all_streams_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(x, total_steps):\n",
    "    step_value = 1/total_steps\n",
    "    return 1 - (x * step_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constant(x, total_steps):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similar_streams_based_on_history(viewed_streams, weight_pattern = linear, max_similar_streams = 10, max_viewed_streams_to_consider = 5):\n",
    "    \"\"\"\n",
    "        viewed_streams: list of stream IDs that have been viewed by the current user. The streams at a lower ID has been viewed more recently. So stream with ID 0 is the last viewed stream.\n",
    "        weight_pattern: The weight pattern to weight the contributions due to the stream history\n",
    "    max_similar_streams: The maximum number of similar streams to return\n",
    "    max_viewed_streams_to_consider: The maximum number of viewed streams to consider for the recommendation \n",
    "    \n",
    "    Returns: A list of stream ID, score pairs\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if viewed_streams:\n",
    "        num_viewed_streams = len(viewed_streams)\n",
    "        \n",
    "        # set the max viewed streams to consider \n",
    "        max_viewed_streams_to_consider = min(max_viewed_streams_to_consider, num_viewed_streams)\n",
    "        \n",
    "        # create an array of 0's\n",
    "        similarity_sum = np.zeros(similarities.shape[0])\n",
    "    \n",
    "        for x, viewed_stream in enumerate(viewed_streams):\n",
    "            stream_index = stream_content_df[stream_content_df[\"StreamID\"]==viewed_stream].index[0]\n",
    "            weight_factor = weight_pattern(x, max_viewed_streams_to_consider)\n",
    "            # print(weight_factor)\n",
    "            similarity_sum = similarity_sum + (weight_factor * np.array(similarities[stream_index]))\n",
    "        \n",
    "        \n",
    "        #print(similarity_sum)\n",
    "        stream_ids = stream_content_df[\"StreamID\"]\n",
    "        \n",
    "        # concatenate the stream ID and the similarity score sum as pairs\n",
    "        stream_similarity = list(zip(stream_ids, similarity_sum))\n",
    "        \n",
    "        # print(stream_similarity)\n",
    "        \n",
    "        # sort the stream similarity on the score in descending order\n",
    "        stream_similarity.sort(key = lambda x: x[1], reverse = True)\n",
    "        \n",
    "        # print(stream_similarity)\n",
    "        \n",
    "        # candidate streams are those which have greater than 0 score and they have not been viewed before\n",
    "        candidate_streams = [x for x in stream_similarity if (x[1] > 0) and (x[0] not in viewed_streams)]\n",
    "        \n",
    "        num_candidate_streams = len(candidate_streams)\n",
    "        \n",
    "        return candidate_streams[:min(num_candidate_streams, max_similar_streams)]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2265, 1.2620715824847637),\n",
       " (199, 1.2362178356915718),\n",
       " (2405, 1.1823430221582885),\n",
       " (2380, 1.1786054440773466),\n",
       " (2373, 1.1267495184586085),\n",
       " (2030, 1.1267286220099606),\n",
       " (2036, 1.1140552834250859),\n",
       " (419, 1.1055542339583908),\n",
       " (1658, 1.071461114797631),\n",
       " (2104, 1.0561773007430364)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_streams_based_on_history([1498, 163, 507, 201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StreamID                                            Content  \\\n",
      "0       163  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...   \n",
      "\n",
      "                                   Content_processed  \n",
      "0  txmak2kzay4 nmeujebo1ac eeutxfhp3go castrol la...  \n",
      "   StreamID                                            Content  \\\n",
      "1       419  TXmAk2KZAy4\\r\\nNMeUjebo1Ac\\r\\nEEuTxFhp3go\\r\\nC...   \n",
      "\n",
      "                                   Content_processed  \n",
      "1  txmak2kzay4 nmeujebo1ac eeutxfhp3go castrol la...  \n"
     ]
    }
   ],
   "source": [
    "print(stream_content_df[stream_content_df[\"StreamID\"] == 163])\n",
    "\n",
    "print(stream_content_df[stream_content_df[\"StreamID\"] == 419])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the content views for the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>163</th>\n",
       "      <th>167</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>...</th>\n",
       "      <th>1657</th>\n",
       "      <th>1658</th>\n",
       "      <th>1659</th>\n",
       "      <th>1660</th>\n",
       "      <th>1661</th>\n",
       "      <th>1662</th>\n",
       "      <th>1665</th>\n",
       "      <th>1668</th>\n",
       "      <th>1670</th>\n",
       "      <th>1677</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920755</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247</td>\n",
       "      <td>0.299320</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.276423</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>0.633962</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249</td>\n",
       "      <td>0.119534</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.373494</td>\n",
       "      <td>0.125749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID       163       167       171       172       173       178  179  \\\n",
       "0     245  1.000000  1.000000  1.000000  1.000000  1.000000  0.920755  0.2   \n",
       "1     246  0.040816  0.000000  0.000000  0.036145  0.000000  0.415094  0.2   \n",
       "2     247  0.299320  0.116279  0.276423  0.457831  0.479042  0.633962  0.4   \n",
       "3     248  0.014577  0.023256  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "4     249  0.119534  0.736434  0.113821  0.373494  0.125749  1.000000  0.2   \n",
       "\n",
       "    184  185  ...   1657  1658  1659  1660  1661  1662  1665  1668  1670  1677  \n",
       "0  0.25  0.0  ...    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  0.00  0.0  ...    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  0.00  0.0  ...    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3  0.00  0.0  ...    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  0.00  0.0  ...    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_views_per_user_scaled_df = pd.read_csv(\"data/content_views_per_user_scaled.csv\", header=0)\n",
    "new_column_names = [\"UserID\"]\n",
    "new_column_names.extend(content_views_per_user_scaled_df.columns[1:])\n",
    "content_views_per_user_scaled_df.columns = new_column_names\n",
    "content_views_per_user_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 219)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = content_views_per_user_scaled_df.drop(\"UserID\", axis=1)\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "user_similarities = euclidean_distances(features_df.values)\n",
    "user_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similar_streams_based_on_other_users(current_user_id, max_similar_streams = 10, max_users_to_consider = 5):\n",
    "    \"\"\"\n",
    "        current_user_id: The ID of the current user.\n",
    "        max_similar_streams: The maximum number of similar streams to return\n",
    "    max_users_to_consider: The maximum number of users to consider\n",
    "    \n",
    "    Returns: A list of stream IDs based on similar users who have watched the most\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if current_user_id:\n",
    "        userid_index = (content_views_per_user_scaled_df[content_views_per_user_scaled_df[\"UserID\"] == current_user_id].index[0])\n",
    "        distance_current_user_other_users = user_similarities[userid_index]\n",
    "        distance_current_user_other_users = np.squeeze(distance_current_user_other_users)\n",
    "        #print(distance_current_user_other_users)\n",
    "        \n",
    "        user_ids = content_views_per_user_scaled_df[\"UserID\"].values\n",
    "        #print(type(user_ids))\n",
    "        #print(user_ids.shape)\n",
    "        #print(distance_current_user_other_users.shape)\n",
    "        \n",
    "        # concatenate the user ID and the similarity score sum as pairs\n",
    "        user_similarity = list(zip(user_ids, distance_current_user_other_users))\n",
    "        \n",
    "        #print(user_similarity)\n",
    "        \n",
    "        # sort the user similarity on the score in ascending order\n",
    "        user_similarity.sort(key = lambda x: x[1])\n",
    "        \n",
    "        #print(user_similarity)\n",
    "        \n",
    "        # candidate users are those which are other users closest to the current user\n",
    "        candidate_users = [x for x in user_similarity if (x[0] != current_user_id)]\n",
    "        \n",
    "        num_candidate_users = len(candidate_users)\n",
    "        candidate_users = candidate_users[:min(num_candidate_users, max_similar_streams)]\n",
    "        print(type(candidate_users[0]))\n",
    "        \n",
    "        # create an array of 0's equal to the number of columns other than UserID (# of streams)\n",
    "        stream_views_sum = np.zeros(features_df.shape[1])\n",
    "        \n",
    "        # get the sum of the views\n",
    "        for x, candidate_user in enumerate(candidate_users):\n",
    "            \n",
    "            # convert the distance to a similarity measure\n",
    "            weight_factor = 1/ (1 + candidate_user[1])\n",
    "            \n",
    "            print(weight_factor)\n",
    "            stream_views_for_user = np.array(content_views_per_user_scaled_df[content_views_per_user_scaled_df[\"UserID\"] == candidate_user[0]].values)\n",
    "            stream_views_sum = stream_views_sum + (weight_factor * stream_views_for_user)\n",
    "        \n",
    "        \n",
    "        stream_ids = features_df.columns\n",
    "        \n",
    "        # concatenate the stream ID and the view score sum as pairs\n",
    "        streams_with_sum_views = list(zip(stream_ids, stream_views_sum))\n",
    "        \n",
    "        \n",
    "        # sort the stream views on the sum in descending order\n",
    "        streams_with_sum_views.sort(key = lambda x: x[1], reverse = True)\n",
    "        \n",
    "        print(streams_with_sum_views)\n",
    "        \n",
    "        # candidate streams are those which have greater than 0 views\n",
    "        candidate_streams = [x for x in stream_similarity if (x[1] > 0)]\n",
    "        \n",
    "        num_candidate_streams = len(candidate_streams)\n",
    "        \n",
    "        return candidate_streams[:min(num_candidate_streams, max_similar_streams)]\n",
    "            \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "0.520338714702191\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (153,) (0,154) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-8727feb3f3c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_similar_streams_based_on_other_users\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m249\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-135-64dd60ba4c58>\u001b[0m in \u001b[0;36mget_similar_streams_based_on_other_users\u001b[1;34m(current_user_id, max_similar_streams, max_users_to_consider)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mstream_views_for_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_views_per_user_scaled_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontent_views_per_user_scaled_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"UserID\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcandidate_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mstream_views_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream_views_sum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mweight_factor\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstream_views_for_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (153,) (0,154) "
     ]
    }
   ],
   "source": [
    "get_similar_streams_based_on_other_users(249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
