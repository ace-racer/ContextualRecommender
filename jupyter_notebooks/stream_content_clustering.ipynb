{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_details():\n",
    "    print(\"Reading the stream details...\")\n",
    "    complete_stream_details_df = pd.read_csv(\"H:\\\\TeamStreamz_IW\\\\code\\\\data\\\\card_module_details_content_extracted.csv\", encoding=\"ISO-8859-1\")\n",
    "    if complete_stream_details_df is not None:\n",
    "        complete_stream_details_dict = {}\n",
    "        _stream_id_stream_title_dict = {}\n",
    "        for _, row in complete_stream_details_df.iterrows():\n",
    "            \n",
    "            stream_id = str(row[\"DECKID\"])\n",
    "            stream_title = str(row[\"DECKNAME\"])\n",
    "            row_content = str(row[\"HTML_CONTENT\"])\n",
    "\n",
    "            # TODO: add the card title and the module name to the content on which the tags can be generated\n",
    "            card_title =str(row[\"CARDTITLE\"])\n",
    "            module_name = str(row[\"MODULENAME\"])\n",
    "            \n",
    "            if row_content and \"nan\" not in row_content:\n",
    "                # if the stream ID already exists in the dictionary\n",
    "                if complete_stream_details_dict.get(stream_id):\n",
    "                    existing_content = complete_stream_details_dict[stream_id]\n",
    "                    new_content = existing_content + \"\\n\" + row_content.strip()\n",
    "                    complete_stream_details_dict[stream_id] = new_content\n",
    "                else:\n",
    "                    complete_stream_details_dict[stream_id] = row_content.strip()\n",
    "                    _stream_id_stream_title_dict[stream_id] = stream_title\n",
    "        \n",
    "        return complete_stream_details_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the stream details...\n"
     ]
    }
   ],
   "source": [
    "stream_details_dict = get_stream_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StreamID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507</td>\n",
       "      <td>wBYKUgUyGWc\\nA team of world-class drivers, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>Castrol EDGE  is Castrols flagship power bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>Charles Cheers Wakefield, Castrols founder,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StreamID                                            Content\n",
       "0      163  TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...\n",
       "1      419  TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...\n",
       "2      507  wBYKUgUyGWc\\nA team of world-class drivers, po...\n",
       "3      199  Castrol EDGE  is Castrols flagship power bran...\n",
       "4      201  Charles Cheers Wakefield, Castrols founder,..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori = pd.DataFrame(list(stream_details_dict.items()), columns=[\"StreamID\", \"Content\"])\n",
    "df_ori.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the existing text data in the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 2)\n",
      "(97, 2)\n",
      "Removed 16 duplicates (based on Content)\n"
     ]
    }
   ],
   "source": [
    "print(df_ori.shape)\n",
    "df = df_ori.drop_duplicates(['Content'])\n",
    "print(df.shape)\n",
    "print(\"Removed {0} duplicates (based on Content)\".format(df_ori.shape[0]-df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...\n",
       "1    TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...\n",
       "2    wBYKUgUyGWc\\nA team of world-class drivers, po...\n",
       "3    Castrol EDGE  is Castrols flagship power bran...\n",
       "4    Charles Cheers Wakefield, Castrols founder,...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Content\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[\"Content\"] = df[\"Content\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokens):\n",
    "    tokens_nop = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens_nop = [t.lower() for t in tokens_nop]\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    stop = stopwords.words('english')\n",
    "    tokens_nostop = [t for t in tokens_nop if t not in stop]\n",
    "    tokens_lem = [wnl.lemmatize(t) for t in tokens_nostop]\n",
    "    tokens_clean = [t for t in tokens_lem if len(t) >= 3]\n",
    "    return tokens_clean\n",
    "\n",
    "def plotWC(tokens):\n",
    "    text_clean = \" \".join(tokens)\n",
    "    print(text_clean)\n",
    "    wc = WordCloud(background_color=\"white\").generate(text_clean)\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(20, 9))\n",
    "    fd = nltk.FreqDist(tokens)  # case sensitive!\n",
    "    fd.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StreamID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_token</th>\n",
       "      <th>Content_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163</td>\n",
       "      <td>TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...</td>\n",
       "      <td>[TXmAk2KZAy4, NMeUjebo1Ac, EEuTxFhp3go, Castro...</td>\n",
       "      <td>[txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...</td>\n",
       "      <td>[TXmAk2KZAy4, NMeUjebo1Ac, EEuTxFhp3go, Castro...</td>\n",
       "      <td>[txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507</td>\n",
       "      <td>wBYKUgUyGWc\\nA team of world-class drivers, po...</td>\n",
       "      <td>[wBYKUgUyGWc, A, team, of, world-class, driver...</td>\n",
       "      <td>[wbykuguygwc, team, world-class, driver, power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>Castrol EDGE  is Castrols flagship power bran...</td>\n",
       "      <td>[Castrol, EDGE, is, Castrols, flagship, power...</td>\n",
       "      <td>[castrol, edge, castrols, flagship, power, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>Charles Cheers Wakefield, Castrols founder,...</td>\n",
       "      <td>[Charles, Cheers, Wakefield, ,, Castrols, f...</td>\n",
       "      <td>[charles, cheers, wakefield, castrols, foun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StreamID                                            Content  \\\n",
       "0      163  TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...   \n",
       "1      419  TXmAk2KZAy4\\nNMeUjebo1Ac\\nEEuTxFhp3go\\nCastrol...   \n",
       "2      507  wBYKUgUyGWc\\nA team of world-class drivers, po...   \n",
       "3      199  Castrol EDGE  is Castrols flagship power bran...   \n",
       "4      201  Charles Cheers Wakefield, Castrols founder,...   \n",
       "\n",
       "                                       Content_token  \\\n",
       "0  [TXmAk2KZAy4, NMeUjebo1Ac, EEuTxFhp3go, Castro...   \n",
       "1  [TXmAk2KZAy4, NMeUjebo1Ac, EEuTxFhp3go, Castro...   \n",
       "2  [wBYKUgUyGWc, A, team, of, world-class, driver...   \n",
       "3  [Castrol, EDGE, is, Castrols, flagship, power...   \n",
       "4  [Charles, Cheers, Wakefield, ,, Castrols, f...   \n",
       "\n",
       "                                   Content_processed  \n",
       "0  [txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...  \n",
       "1  [txmak2kzay4, nmeujebo1ac, eeutxfhp3go, castro...  \n",
       "2  [wbykuguygwc, team, world-class, driver, power...  \n",
       "3  [castrol, edge, castrols, flagship, power, br...  \n",
       "4  [charles, cheers, wakefield, castrols, foun...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content_token'] = df['Content'].map(word_tokenize)\n",
    "df['Content_processed'] = df.Content_token.apply(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 684)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df['Content_processedtext'] = df.Content_processed.apply(lambda x: ' '.join(x))\n",
    "\n",
    "vec_tfidf = TfidfVectorizer(max_df=0.7, min_df=3, use_idf=True)\n",
    "content_tfidf = vec_tfidf.fit_transform(df['Content_processedtext'])\n",
    "print(content_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the dimensions for easier computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Use SVD to reduce dimensions to 50% features - try values between 25-50 for 70 to 100%\n",
    "svd = TruncatedSVD(30)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_lsa = lsa.fit_transform(content_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 81%\n"
     ]
    }
   ],
   "source": [
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.99 ms\n",
      "Clusters: 3\n",
      "Silhouette Coefficient for clusters: 0.160\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "num_clusters = 3\n",
    "\n",
    "for num in [num_clusters]:\n",
    "    km3 = KMeans(n_clusters=num, init='k-means++', max_iter=1000, n_init=1, random_state=1)\n",
    "    %time km3.fit(X_lsa)\n",
    "    # The higher the better (-1 to 1)\n",
    "    print(\"Clusters: {0}\".format(num))\n",
    "    print(\"Silhouette Coefficient for clusters: %0.3f\"\n",
    "          % metrics.silhouette_score(X_lsa, km3.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: oil edge engine titanium strength pressure fst technology car new\n",
      "Cluster 1: sequence name field1 type text point app redemption zoom page1\n",
      "Cluster 2: engine sludge gtx protection part start oilways magnatec critical warm\n"
     ]
    }
   ],
   "source": [
    "def print_terms(cm, num):\n",
    "    original_space_centroids = svd.inverse_transform(cm.cluster_centers_)\n",
    "    order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    terms = vec_tfidf.get_feature_names()\n",
    "    for i in range(num):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()\n",
    "\n",
    "print_terms(km3, num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the co-occurences of different terms in the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = {}\n",
    "\n",
    "for content_tokens in df['Content_processed']:\n",
    "    for word1 in content_tokens:\n",
    "        \n",
    "        if not sparse_matrix.get(word1):\n",
    "            sparse_matrix[word1] = {}\n",
    "\n",
    "        for word2 in content_tokens:\n",
    "            if sparse_matrix[word1].get(word2):\n",
    "                sparse_matrix[word1][word2] += 1\n",
    "            else:\n",
    "                sparse_matrix[word1][word2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('castrol,gtx', 978),\n",
       " ('engine,critical', 968),\n",
       " ('engine,warm-up', 918),\n",
       " ('...,point', 880),\n",
       " ('castrol,sludge', 860),\n",
       " ('oil,edge', 834),\n",
       " ('point,transaction', 824),\n",
       " ('product,point', 806),\n",
       " ('castrol,edge', 798),\n",
       " ('point,code', 790),\n",
       " ('engine,molecule', 778),\n",
       " ('oil,titanium', 774),\n",
       " ('...,incentive', 774),\n",
       " ('product,incentive', 730),\n",
       " ('incentive,transaction', 730),\n",
       " ('redemption,transaction', 728),\n",
       " ('engine,time', 726),\n",
       " ('castrol,point', 722),\n",
       " ('incentive,code', 710),\n",
       " ('engine,intelligent', 704),\n",
       " ('...,redemption', 694),\n",
       " ('point,click', 686),\n",
       " ('oil,pressure', 672),\n",
       " ('redemption,click', 666),\n",
       " ('product,redemption', 662),\n",
       " ('oil,strength', 656),\n",
       " ('engine,car', 650),\n",
       " ('code,redemption', 646),\n",
       " ('castrol,titanium', 642),\n",
       " ('castrol,part', 624),\n",
       " ('redemption,request', 624),\n",
       " ('point,request', 608),\n",
       " ('castrol,incentive', 592),\n",
       " ('point,user', 586),\n",
       " ('incentive,click', 584),\n",
       " ('engine,high', 580),\n",
       " ('castrol,strength', 578),\n",
       " ('engine,cling', 578),\n",
       " ('point,sale', 576),\n",
       " ('engine,edge', 568),\n",
       " ('titanium,edge', 566),\n",
       " ('castrol,redemption', 556),\n",
       " ('engine,damage', 556),\n",
       " ('engine,wear', 554),\n",
       " ('engine,double', 546),\n",
       " ('sludge,oilways', 542),\n",
       " ('castrol,pressure', 540),\n",
       " ('titanium,engine', 540),\n",
       " ('engine,like', 536),\n",
       " ('redemption,user', 536)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter()\n",
    "co_occurance_threshold = 1000\n",
    "for word1 in sparse_matrix:\n",
    "    for word2, co_occurence_count in sparse_matrix[word1].items():\n",
    "        current_key_1 = \"{0},{1}\".format(word1, word2)\n",
    "        current_key_2 = \"{0},{1}\".format(word2, word1)\n",
    "        \n",
    "        if word1 != word2 and co_occurence_count <= co_occurance_threshold:\n",
    "            if counts.get(current_key_1):\n",
    "                counts[current_key_1] += co_occurence_count // 2\n",
    "            elif counts.get(current_key_2):\n",
    "                counts[current_key_2] += co_occurence_count // 2\n",
    "            else:\n",
    "                counts[current_key_1] = co_occurence_count // 2\n",
    "        \n",
    "counts.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
